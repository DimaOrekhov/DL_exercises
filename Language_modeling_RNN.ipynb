{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArticlesFeb2017.csv',\n",
       " 'CommentsFeb2018.csv',\n",
       " 'ArticlesApril2017.csv',\n",
       " 'CommentsApril2018.csv',\n",
       " 'ArticlesMarch2018.csv',\n",
       " 'CommentsMarch2017.csv',\n",
       " 'ArticlesMay2017.csv',\n",
       " 'ArticlesJan2017.csv',\n",
       " 'CommentsJan2018.csv',\n",
       " 'CommentsMarch2018.csv',\n",
       " 'ArticlesJan2018.csv',\n",
       " 'CommentsMay2017.csv',\n",
       " 'CommentsJan2017.csv',\n",
       " 'ArticlesMarch2017.csv',\n",
       " 'CommentsApril2017.csv',\n",
       " 'ArticlesFeb2018.csv',\n",
       " 'CommentsFeb2017.csv',\n",
       " 'ArticlesApril2018.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('Data/nyt-comments/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Data/nyt-comments/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8603\n"
     ]
    }
   ],
   "source": [
    "headlines = []\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if 'Articles' in filename:\n",
    "        curr = pd.read_csv(os.path.join(DATA_DIR, filename))\n",
    "        headlines += list(curr['headline'].values)\n",
    "headlines = [hl for hl in headlines if hl != 'Unknown']\n",
    "print(len(headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    res = \"\".join(ch for ch in x if ch not in string.punctuation).lower()\n",
    "    res = res.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [preprocess(x) for x in headlines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pre-trained GLOVE embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_FILE = 'Data/glove/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        self.unique_tokens = set(['PAD', '<\\s>'])\n",
    "        self.new_corpus = []\n",
    "        print('Getting unique tokens')\n",
    "        for i, sentence in tqdm_notebook(enumerate(corpus)):\n",
    "            [self.unique_tokens.add(word) for word in sentence.split()]\n",
    "            self.new_corpus.append(sentence + ' <\\s>')\n",
    "            \n",
    "    def filter_embeddings(self, emb_file):\n",
    "        self.words = ['PAD', '<\\s>']\n",
    "        self.vecs = []\n",
    "        print('Filtering embeddings')\n",
    "        with open(emb_file) as fn:\n",
    "            for line in tqdm_notebook(fn):\n",
    "                line = line.strip().split(' ')\n",
    "                if line[0] in self.unique_tokens:\n",
    "                    self.words.append(line[0])\n",
    "                    self.vecs.append(np.array([float(num) for num in line[1:]]))\n",
    "        self.vecs.insert(0, np.random.randn(*self.vecs[0].shape))\n",
    "        self.vecs.insert(0, np.random.randn(*self.vecs[0].shape))\n",
    "        self.index_dic = {word:i for i, word in enumerate(self.words)}\n",
    "        \n",
    "    def tokenize(self):\n",
    "        self.tokenized = []\n",
    "        for sentence in self.new_corpus:\n",
    "            t_seq = []\n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    token = self.index_dic[word]\n",
    "                    t_seq.append(token)\n",
    "                except:\n",
    "                    new_index = len(self.index_dic)\n",
    "                    self.index_dic[word] = new_index\n",
    "                    t_seq.append(new_index)\n",
    "                    self.vecs.append(np.random.randn(*self.vecs[0].shape))\n",
    "                    assert(len(self.index_dic) == len(self.vecs))\n",
    "            self.tokenized.append(t_seq)\n",
    "        self.inv_dic = {v:k for k, v in self.index_dic.items()}\n",
    "        return self.tokenized, np.vstack(self.vecs).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting unique tokens\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572626d766c54ce19125b1eba03d1d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011fc03fcb0443f3986d546e5d7b1826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.filter_embeddings(EMB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus, vecs = tokenizer.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in tokenizer.tokenized])\n",
    "plt.title('Length of sentences in data set')\n",
    "_ = plt.xlabel('Number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenized):\n",
    "        self.tokenized = [torch.tensor(seq) for seq in tokenized]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if type(idx) == slice:\n",
    "            #Dataloader doesn't use slices \n",
    "            #Thus this piece of code isn't used\n",
    "            #Left if one would lije to modify overall pipeline and work with slices\n",
    "            x = self.tokenized[idx]\n",
    "            y = [seq[1:] for seq in x]\n",
    "            x = [seq[:-1] for seq in x]\n",
    "            lengths = [len(seq) for seq in x]\n",
    "            x = pad_sequence(x) #from torch.nn.utils.rnn\n",
    "            y = pad_sequence(y)\n",
    "            return x, y, lengths\n",
    "        elif type(idx) == int:\n",
    "            x = self.tokenized[idx][:-1]\n",
    "            y = self.tokenized[idx][1:]\n",
    "            length = len(x)\n",
    "            return x, y, length\n",
    "        else:\n",
    "            raise TypeError('Incorrect index type')\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "def custom_collate(data):\n",
    "    data = sorted(data, key=lambda x: x[2], reverse=True) #Consider whether you need enforce_sorted=True\n",
    "    x, y, lengths = zip(*data)\n",
    "    x = pad_sequence(x)\n",
    "    y = pad_sequence(y)\n",
    "    return x, y, lengths\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, h_size, train_emb=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embeddings))\n",
    "        self.vocab_size = embeddings.shape[0]\n",
    "        self.train_emb = train_emb\n",
    "        if train_emb:\n",
    "            self.embedding.weight.requires_grad = True # if we want to continue training\n",
    "            parameters = self.parameters()\n",
    "        else:\n",
    "            parameters = filter(lambda x: x.requires_grad, self.parameters())\n",
    "            \n",
    "        self.h_size = h_size\n",
    "        self.lstm = nn.LSTM(embeddings.shape[1], h_size)\n",
    "        self.hidden = None\n",
    "        self.fc = nn.Linear(h_size, self.vocab_size)\n",
    "        self.lsm = nn.LogSoftmax(dim=-1)\n",
    "        #self.asm = nn.AdaptiveLogSoftmaxWithLoss() #Consider!\n",
    "\n",
    "        self.opt = torch.optim.Adam(parameters)\n",
    "        self.loss_fn = torch.nn.NLLLoss(reduction='mean')\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        self.hidden = [torch.randn((1, batch_size, self.h_size)).type('torch.FloatTensor') for _ in range(2)]\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x = pack_padded_sequence(x, lengths)\n",
    "        x, self.hidden = self.lstm(x, self.hidden)\n",
    "        x, pl = pad_packed_sequence(x)\n",
    "        x = self.lsm(self.fc(x))\n",
    "        return x, pl\n",
    "    \n",
    "    def fit(self, dataset, n_epochs, batch_size):\n",
    "        dl = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "        for i in tqdm_notebook(range(n_epochs)):\n",
    "            r_loss = 0\n",
    "            j = 0\n",
    "            for x_batch, y_batch, lengths in dl:\n",
    "                #print(j)\n",
    "                bs = x_batch.shape[1]\n",
    "                self.init_hidden(bs)\n",
    "                #out, _ = self.forward(x_batch, lengths)\n",
    "                try:\n",
    "                    out, _ = self.forward(x_batch, lengths)\n",
    "                except:\n",
    "                    return x_batch, y_batch, lengths\n",
    "                self.opt.zero_grad()\n",
    "                try:\n",
    "                    loss_val = self.loss_fn(out.view(-1, self.vocab_size), y_batch.flatten())\n",
    "                except:\n",
    "                    print(i, j)\n",
    "                    return x_batch, y_batch, lengths, out\n",
    "                loss_val.backward()\n",
    "                self.opt.step()\n",
    "                \n",
    "                r_loss += loss_val.item()\n",
    "                j += 1\n",
    "            print(f'Epoch {i}, loss: {round(r_loss/j, 5)}')\n",
    "            \n",
    "    def generate(self, start_word, tokenizer, sample=False):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            curr_index = tokenizer.index_dic[start_word]\n",
    "            self.init_hidden(1)\n",
    "            sequence = [curr_index]\n",
    "            while curr_index != 1: #1 is EOS index\n",
    "                curr_tensor = torch.tensor([curr_index]).view(1, 1)\n",
    "                out, _ = self(curr_tensor, [1])\n",
    "                if sample:\n",
    "                    curr_index = np.random.choice(out.shape[-1], p=out.flatten().exp().numpy())\n",
    "                else:\n",
    "                    curr_index = torch.argmax(out).item()\n",
    "                sequence.append(curr_index)\n",
    "            sequence = ' '.join([tokenizer.inv_dic[idx] for idx in sequence])\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(vecs, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73935a591bc499592c28a138c75a5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 8.08627\n",
      "Epoch 1, loss: 7.44987\n",
      "Epoch 2, loss: 7.13129\n",
      "Epoch 3, loss: 6.81872\n",
      "Epoch 4, loss: 6.5097\n",
      "Epoch 5, loss: 6.1968\n",
      "Epoch 6, loss: 5.88512\n",
      "Epoch 7, loss: 5.57657\n",
      "Epoch 8, loss: 5.27119\n",
      "Epoch 9, loss: 4.9825\n",
      "Epoch 10, loss: 4.69003\n",
      "Epoch 11, loss: 4.41025\n",
      "Epoch 12, loss: 4.15464\n",
      "Epoch 13, loss: 3.93017\n",
      "Epoch 14, loss: 3.71844\n",
      "Epoch 15, loss: 3.56279\n",
      "Epoch 16, loss: 3.44058\n",
      "Epoch 17, loss: 3.34048\n",
      "Epoch 18, loss: 3.23965\n",
      "Epoch 19, loss: 3.1692\n",
      "Epoch 20, loss: 3.11802\n",
      "Epoch 21, loss: 3.08116\n",
      "Epoch 22, loss: 3.04657\n",
      "Epoch 23, loss: 2.99471\n",
      "Epoch 24, loss: 2.98284\n",
      "Epoch 25, loss: 2.94257\n",
      "Epoch 26, loss: 2.92351\n",
      "Epoch 27, loss: 2.88537\n",
      "Epoch 28, loss: 2.86145\n",
      "Epoch 29, loss: 2.85256\n",
      "Epoch 30, loss: 2.82741\n",
      "Epoch 31, loss: 2.79446\n",
      "Epoch 32, loss: 2.79359\n",
      "Epoch 33, loss: 2.77608\n",
      "Epoch 34, loss: 2.75567\n",
      "Epoch 35, loss: 2.71963\n",
      "Epoch 36, loss: 2.71617\n",
      "Epoch 37, loss: 2.70122\n",
      "Epoch 38, loss: 2.69524\n",
      "Epoch 39, loss: 2.67492\n",
      "Epoch 40, loss: 2.67589\n",
      "Epoch 41, loss: 2.6662\n",
      "Epoch 42, loss: 2.6493\n",
      "Epoch 43, loss: 2.64231\n",
      "Epoch 44, loss: 2.61218\n",
      "Epoch 45, loss: 2.61636\n",
      "Epoch 46, loss: 2.5992\n",
      "Epoch 47, loss: 2.59085\n",
      "Epoch 48, loss: 2.58783\n",
      "Epoch 49, loss: 2.56724\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(dataset, N_EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world endings gently <\\s>\n",
      "world rise flynns bookworms eating <\\s>\n",
      "world interests spending for the focus <\\s>\n",
      "world at veterans affairs up trying shutdown gentrification <\\s>\n",
      "world am preparing in school shooting vs meets railroads <\\s>\n",
      "world cup politics <\\s>\n",
      "world to transgender wages <\\s>\n",
      "world men held jail <\\s>\n",
      "world invites is wrong are again <\\s>\n",
      "world a happy latest spectators maligning full neighbors all of flood widens problems <\\s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model.generate('world', tokenizer, sample=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world of the world <\\s>\n",
      "world of the world <\\s>\n",
      "world to the world <\\s>\n",
      "world <\\s>\n",
      "world of the world <\\s>\n",
      "world fiddler <\\s>\n",
      "world of the world <\\s>\n",
      "world of the world <\\s>\n",
      "world of the world <\\s>\n",
      "world bridges <\\s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model.generate('world', tokenizer, sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york today for approach <\\s>\n",
      "new york today to china with get labor students 26 <\\s>\n",
      "new first upper east starbucks with caffeine athletes <\\s>\n",
      "new york today documenting tips for blood was police its a personal touch <\\s>\n",
      "new  moments <\\s>\n",
      "new york today google feel theyre checkpoints easy presidential muscle inquiry <\\s>\n",
      "new york today taxpayer <\\s>\n",
      "new york our coming with all some kids her 8 my husbands <\\s>\n",
      "new challenges query hope to end at moods <\\s>\n",
      "new york today lesson a fun <\\s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model.generate('new', tokenizer, sample=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n",
      "new york today a new of a liquid <\\s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(model.generate('new', tokenizer, sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
